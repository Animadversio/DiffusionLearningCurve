{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30100b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad20b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.auto import trange, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionLearningCurve\")\n",
    "sys.path.append(\"/Users/binxuwang/Github/DiffusionLearningCurve/\")\n",
    "from core.diffusion_nn_lib import UNetBlockStyleMLP_backbone\n",
    "from core.toy_shape_dataset_lib import generate_random_star_shape_torch\n",
    "from core.diffusion_basics_lib import *\n",
    "from core.diffusion_edm_lib import *\n",
    "from core.network_edm_lib import SongUNet, DhariwalUNet\n",
    "from core.DiT_model_lib import *\n",
    "from core.diffusion_nn_lib import UNetBlockStyleMLP_backbone\n",
    "from circuit_toolkit.plot_utils import saveallforms, to_imgrid, show_imgrid\n",
    "from pprint import pprint\n",
    "\n",
    "saveroot = f\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiffusionSpectralLearningCurve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f518283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of trainable parameters in the Score Model: 2570243\n",
      "total number of parameters in the Score Model: 2570243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_666950/1899011077.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet.load_state_dict(torch.load(join(savedir, \"model_final.pth\")))\n"
     ]
    }
   ],
   "source": [
    "from core.network_edm_lib import SongUNet, DhariwalUNet, create_unet_model\n",
    "from core.diffusion_edm_lib import UNetBlockStyleMLP_backbone, EDMPrecondWrapper, EDMCNNPrecondWrapper, EDMDiTPrecondWrapper\n",
    "import json\n",
    "from easydict import EasyDict as edict\n",
    "expname = \"FFHQ32_UNet_CNN_EDM_1blocks_1x_wide128_fixednorm\"\n",
    "savedir = join(saveroot, expname)\n",
    "# model_dict = torch.load(join(expdir, \"model_final.pth\"))\n",
    "config = json.load(open(join(savedir, \"config.json\")))\n",
    "unet = create_unet_model(edict(config))\n",
    "unet.load_state_dict(torch.load(join(savedir, \"model_final.pth\")))\n",
    "model_precd_CNN = EDMCNNPrecondWrapper(unet, sigma_data=0.5, sigma_min=0.002, sigma_max=80, rho=7.0)\n",
    "model_precd_CNN = model_precd_CNN.to(\"cuda\").eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82880689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channels': 3,\n",
       " 'img_size': 32,\n",
       " 'layers_per_block': 1,\n",
       " 'decoder_init_attn': True,\n",
       " 'attn_resolutions': [0],\n",
       " 'model_channels': 128,\n",
       " 'channel_mult': [1],\n",
       " 'dropout': 0.0,\n",
       " 'label_dim': 0,\n",
       " 'augment_dim': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923d4bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (32x32_in0): UNetBlock(\n",
       "    (norm0): GroupNorm()\n",
       "    (conv0): Conv2d()\n",
       "    (affine): Linear()\n",
       "    (norm1): GroupNorm()\n",
       "    (conv1): Conv2d()\n",
       "    (norm2): GroupNorm()\n",
       "    (qkv): Conv2d()\n",
       "    (proj): Conv2d()\n",
       "  )\n",
       "  (32x32_in1): UNetBlock(\n",
       "    (norm0): GroupNorm()\n",
       "    (conv0): Conv2d()\n",
       "    (affine): Linear()\n",
       "    (norm1): GroupNorm()\n",
       "    (conv1): Conv2d()\n",
       "  )\n",
       "  (32x32_block0): UNetBlock(\n",
       "    (norm0): GroupNorm()\n",
       "    (conv0): Conv2d()\n",
       "    (affine): Linear()\n",
       "    (norm1): GroupNorm()\n",
       "    (conv1): Conv2d()\n",
       "    (skip): Conv2d()\n",
       "  )\n",
       "  (32x32_block1): UNetBlock(\n",
       "    (norm0): GroupNorm()\n",
       "    (conv0): Conv2d()\n",
       "    (affine): Linear()\n",
       "    (norm1): GroupNorm()\n",
       "    (conv1): Conv2d()\n",
       "    (skip): Conv2d()\n",
       "  )\n",
       "  (32x32_aux_norm): GroupNorm()\n",
       "  (32x32_aux_conv): Conv2d()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae5cc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.enc[\"32x32_conv\"].out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb691ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.network_edm_lib import UNetBlock, PositionalEmbedding, FourierEmbedding, Linear, Conv2d, GroupNorm, silu\n",
    "class SongUNetResNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        img_resolution,                     # Image resolution at input/output.\n",
    "        in_channels,                        # Number of color channels at input.\n",
    "        out_channels,                       # Number of color channels at output.\n",
    "        label_dim           = 0,            # Number of class labels, 0 = unconditional.\n",
    "        augment_dim         = 0,            # Augmentation label dimensionality, 0 = no augmentation.\n",
    "\n",
    "        model_channels      = 128,          # Base multiplier for the number of channels.\n",
    "        # channel_mult        = 2,    # Per-resolution multipliers for the number of channels.\n",
    "        channel_mult_emb    = 4,            # Multiplier for the dimensionality of the embedding vector.\n",
    "        num_blocks          = 4,            # Number of residual blocks per resolution.\n",
    "        attn_resolutions    = [16],         # List of resolutions with self-attention.\n",
    "        dropout             = 0.10,         # Dropout probability of intermediate activations.\n",
    "        label_dropout       = 0,            # Dropout probability of class labels for classifier-free guidance.\n",
    "        # decoder_init_attn   = True,         # NEW ARGS, whether to add attn in the first decoder block\n",
    "        embedding_type      = 'positional', # Timestep embedding type: 'positional' for DDPM++, 'fourier' for NCSN++.\n",
    "        channel_mult_noise  = 1,            # Timestep embedding size: 1 for DDPM++, 2 for NCSN++.\n",
    "        encoder_type        = 'standard',   # Encoder architecture: 'standard' for DDPM++, 'residual' for NCSN++.\n",
    "        decoder_type        = 'standard',   # Decoder architecture: 'standard' for both DDPM++ and NCSN++.\n",
    "        resample_filter     = [1,1],        # Resampling filter: [1,1] for DDPM++, [1,3,3,1] for NCSN++.\n",
    "    ):\n",
    "        assert embedding_type in ['fourier', 'positional']\n",
    "        assert encoder_type in ['standard', 'skip', 'residual']\n",
    "        assert decoder_type in ['standard', 'skip']\n",
    "\n",
    "        super().__init__()\n",
    "        self.label_dropout = label_dropout\n",
    "        emb_channels = model_channels * channel_mult_emb\n",
    "        noise_channels = model_channels * channel_mult_noise\n",
    "        init = dict(init_mode='xavier_uniform')\n",
    "        init_zero = dict(init_mode='xavier_uniform', init_weight=1e-5)\n",
    "        init_attn = dict(init_mode='xavier_uniform', init_weight=np.sqrt(0.2))\n",
    "        block_kwargs = dict(\n",
    "            emb_channels=emb_channels, num_heads=1, dropout=dropout, skip_scale=np.sqrt(0.5), eps=1e-6,\n",
    "            resample_filter=resample_filter, resample_proj=True, adaptive_scale=False,\n",
    "            init=init, init_zero=init_zero, init_attn=init_attn,\n",
    "        )\n",
    "\n",
    "        # Mapping.\n",
    "        self.map_noise = PositionalEmbedding(num_channels=noise_channels, endpoint=True) if embedding_type == 'positional' else FourierEmbedding(num_channels=noise_channels)\n",
    "        self.map_label = Linear(in_features=label_dim, out_features=noise_channels, **init) if label_dim else None\n",
    "        self.map_augment = Linear(in_features=augment_dim, out_features=noise_channels, bias=False, **init) if augment_dim else None\n",
    "        self.map_layer0 = Linear(in_features=noise_channels, out_features=emb_channels, **init)\n",
    "        self.map_layer1 = Linear(in_features=emb_channels, out_features=emb_channels, **init)\n",
    "\n",
    "        # Encoder.\n",
    "        self.enc = torch.nn.ModuleDict()\n",
    "        cout = in_channels\n",
    "        caux = in_channels\n",
    "        # for level, mult in enumerate(channel_mult):\n",
    "        res = img_resolution\n",
    "        cin = cout\n",
    "        cout = model_channels\n",
    "        self.enc[f'{res}x{res}_conv'] = Conv2d(in_channels=cin, out_channels=cout, kernel=3, **init)\n",
    "        for idx in range(num_blocks):\n",
    "            cin = cout\n",
    "            cout = model_channels # * channel_mult\n",
    "            attn = (res in attn_resolutions)\n",
    "            self.enc[f'{res}x{res}_block{idx}'] = UNetBlock(in_channels=cin, out_channels=cout, attention=attn, **block_kwargs)\n",
    "\n",
    "        # Decoder.\n",
    "        self.dec = torch.nn.ModuleDict()\n",
    "        self.dec[f'{res}x{res}_aux_norm'] = GroupNorm(num_channels=cout, eps=1e-6)\n",
    "        self.dec[f'{res}x{res}_aux_conv'] = Conv2d(in_channels=cout, out_channels=out_channels, kernel=3, **init_zero)\n",
    "\n",
    "    def forward(self, x, noise_labels, cond, augment_labels=None):\n",
    "        # Mapping.\n",
    "        emb = self.map_noise(noise_labels)\n",
    "        emb = emb.reshape(emb.shape[0], 2, -1).flip(1).reshape(*emb.shape) # swap sin/cos\n",
    "        if self.map_label is not None:\n",
    "            tmp = cond\n",
    "            if self.training and self.label_dropout:\n",
    "                tmp = tmp * (torch.rand([x.shape[0], 1], device=x.device) >= self.label_dropout).to(tmp.dtype)\n",
    "            emb = emb + self.map_label(tmp * np.sqrt(self.map_label.in_features))\n",
    "        if self.map_augment is not None and augment_labels is not None:\n",
    "            emb = emb + self.map_augment(augment_labels)\n",
    "        emb = silu(self.map_layer0(emb))\n",
    "        emb = silu(self.map_layer1(emb))\n",
    "\n",
    "        # Encoder.\n",
    "        aux = x\n",
    "        for name, block in self.enc.items():\n",
    "            if 'aux_down' in name:\n",
    "                aux = block(aux)\n",
    "            elif 'aux_skip' in name:\n",
    "                x = x + block(aux)\n",
    "            elif 'aux_residual' in name:\n",
    "                x = aux = (x + block(aux)) / np.sqrt(2)\n",
    "            else:\n",
    "                x = block(x, emb) if isinstance(block, UNetBlock) else block(x)\n",
    "\n",
    "        # Decoder.\n",
    "        aux = None\n",
    "        tmp = None\n",
    "        for name, block in self.dec.items():\n",
    "            if 'aux_up' in name:\n",
    "                aux = block(aux)\n",
    "            elif 'aux_norm' in name:\n",
    "                tmp = block(x)\n",
    "            elif 'aux_conv' in name:\n",
    "                tmp = block(silu(tmp))\n",
    "                aux = tmp if aux is None else tmp + aux\n",
    "            else:\n",
    "                x = block(x, emb)\n",
    "        return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SongUNetResNet(img_resolution=32, in_channels=3, out_channels=3, \n",
    "               model_channels=128, channel_mult_emb=4, num_blocks=2, \n",
    "               attn_resolutions=[], \n",
    "               dropout=0.1, label_dropout=0, \n",
    "               embedding_type='positional', channel_mult_noise=1, \n",
    "               encoder_type='standard', decoder_type='standard', resample_filter=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25322b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428273b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36496867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
